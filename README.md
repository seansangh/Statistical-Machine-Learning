# Statistical-Machine-Learning

Versions:
- Python 3.11.3


<hr>

Technologies:
- Python
- Matlab
- Jupyter Notebook
- Google Colab
- Pytorch


<hr>

Topics:
<ol><li>Mathematical foundations for machine learning</li>
<li>Maximum likelihood estimation</li>
<li>Naive Bayes classification</li>
<li>Logistic regression</li>
<li>Support vector machines</li>
<li>Probabilistic graphical models</li>
<li>Mixture models</li>
<li>K-means clustering</li>
<li>Spectral clustering</li>
<li>Dimensionality reduction</li>
<li>Principal component analysis</li>
<li>Neural networks and deep learning</li>
<li>Convolutional neural networks</li></ol>

<hr>
<b>Density Estimation & Classification:</b>
<br>
This project involves using a MNIST dataset containing images of digits "0" and "1" and involves four tasks: feature extraction, parameter calculation, implementation of Na√Øve Bayes classifiers, and prediction of labels for the test data using the classifiers. Finally, calculating the accuracy of the predictions.
<br>
<br>
<b>K-Means:</b>
<br>
Use the K-means algorithm to implement two different strategies for choosing initial cluster centers.
<br>
<br>
<b>Neural Networks & Deep Learning:</b>
<br>
Understand the whole process of compiling different layers (Convolutional Layer, Fully-Connected Layer, Pooling Layer, Activation Layer, Loss function) of a simple Convolutional Neural Network (CNN) for the visual classification task. And compile an evaluation code to evaluate the trained CNN to obtain the training and testing results
